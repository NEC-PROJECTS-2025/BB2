{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "22667376-f97d-4512-9309-7fe1a0af1c6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unzipping completed.\n"
     ]
    }
   ],
   "source": [
    "import zipfile\n",
    "\n",
    "# Specify the file name and path of the zip file\n",
    "zip_file_path = 'Gammatonegram.zip'\n",
    "\n",
    "# Specify the path where you want to extract the contents\n",
    "extract_to_path = 'Gammatonegram_images/'\n",
    "\n",
    "# Open the zip file and extract its contents\n",
    "with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:\n",
    "    zip_ref.extractall(extract_to_path)\n",
    "\n",
    "print(\"Unzipping completed.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c66ba49-369e-4809-a588-59c3d6aa4fe6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9b085b35-db65-4d10-9b03-4ec9c6cc7d8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in c:\\users\\dell\\anaconda3\\lib\\site-packages (2.18.0)\n",
      "Requirement already satisfied: tensorflow-intel==2.18.0 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from tensorflow) (2.18.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (2.1.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=24.3.25 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (25.2.10)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (0.6.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (0.2.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (18.1.1)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (3.4.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\dell\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (24.1)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (4.25.3)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (2.32.3)\n",
      "Requirement already satisfied: setuptools in c:\\users\\dell\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (75.1.0)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (2.5.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (4.11.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (1.14.1)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (1.71.0)\n",
      "Requirement already satisfied: tensorboard<2.19,>=2.18 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (2.18.0)\n",
      "Requirement already satisfied: keras>=3.5.0 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (3.9.0)\n",
      "Requirement already satisfied: numpy<2.1.0,>=1.26.0 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (1.26.4)\n",
      "Requirement already satisfied: h5py>=3.11.0 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (3.11.0)\n",
      "Requirement already satisfied: ml-dtypes<0.5.0,>=0.4.0 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (0.4.1)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from astunparse>=1.6.0->tensorflow-intel==2.18.0->tensorflow) (0.44.0)\n",
      "Requirement already satisfied: rich in c:\\users\\dell\\anaconda3\\lib\\site-packages (from keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow) (13.7.1)\n",
      "Requirement already satisfied: namex in c:\\users\\dell\\anaconda3\\lib\\site-packages (from keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow) (0.0.8)\n",
      "Requirement already satisfied: optree in c:\\users\\dell\\anaconda3\\lib\\site-packages (from keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow) (0.14.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.18.0->tensorflow) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.18.0->tensorflow) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.18.0->tensorflow) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.18.0->tensorflow) (2025.1.31)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from tensorboard<2.19,>=2.18->tensorflow-intel==2.18.0->tensorflow) (3.4.1)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from tensorboard<2.19,>=2.18->tensorflow-intel==2.18.0->tensorflow) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from tensorboard<2.19,>=2.18->tensorflow-intel==2.18.0->tensorflow) (3.0.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard<2.19,>=2.18->tensorflow-intel==2.18.0->tensorflow) (2.1.3)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from rich->keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow) (2.2.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from rich->keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow) (2.15.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow) (0.1.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "50c75b9d-4308-4f46-a1b4-3828292e1cec",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tensorflow' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[18], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m tensorflow \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m-\u001b[39mversion\n",
      "\u001b[1;31mNameError\u001b[0m: name 'tensorflow' is not defined"
     ]
    }
   ],
   "source": [
    "tensorflow --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7003c824-a747-45ea-bb7b-f9118f9c41c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, BatchNormalization, Activation\n",
    "from tensorflow.keras.optimizers import SGD, Adagrad, Adadelta, RMSprop, Adam\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eed617c4-f1ba-4aad-866c-a8ab49033c54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the data generators with preprocessing steps\n",
    "train_gen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    horizontal_flip=True\n",
    ")\n",
    "\n",
    "test_gen = ImageDataGenerator(rescale=1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4587a675-7305-4eb3-bb1d-fd8801f08aa5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3240 images belonging to 2 classes.\n",
      "Found 301 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "# Load data\n",
    "train_data = train_gen.flow_from_directory(\n",
    "    'Gammatonegram_images/Gammatone of heart sounds/Gammatone of heart sounds/train',\n",
    "    target_size=(150, 150),\n",
    "    batch_size=32,\n",
    "    class_mode='binary'\n",
    ")\n",
    "\n",
    "test_data = test_gen.flow_from_directory(\n",
    "    'Gammatonegram_images/Gammatone of heart sounds/Gammatone of heart sounds/val',\n",
    "    target_size=(150, 150),\n",
    "    batch_size=32,\n",
    "    class_mode='binary'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5109e338-5de3-46f6-ba8f-9d1c1f5453eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'healthy': 0, 'unhealthy': 1}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.class_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2b447c55-a63f-46f1-aed7-e40b93cfc254",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 0.629126213592233, 1: 2.43609022556391}\n"
     ]
    }
   ],
   "source": [
    "# Calculate class weights\n",
    "y_train = train_data.classes\n",
    "class_weights = compute_class_weight(class_weight='balanced', classes=np.unique(y_train), y=y_train)\n",
    "class_weights = dict(enumerate(class_weights))\n",
    "print(class_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "efe6298a-625d-4dde-94c1-e469c06531a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def create_model():\n",
    "    model = Sequential()\n",
    "\n",
    "\n",
    "    model.add(Conv2D(12, (3, 3), input_shape=(150, 150, 3)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "\n",
    "    model.add(Conv2D(20, (3, 3)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "\n",
    "    model.add(Conv2D(32, (3, 3)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "\n",
    "    model.add(Flatten())\n",
    "\n",
    "\n",
    "    model.add(Dense(128))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dense(64))\n",
    "    model.add(Activation('relu'))\n",
    "\n",
    "\n",
    "    model.add(Dense(2, activation='softmax'))\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "704aa76d-dcec-4fe3-b9f8-6cfc2772e63b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with SGD optimizer\n",
      "Epoch 1/25\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 530ms/step - accuracy: 0.6382 - loss: 0.6859 - val_accuracy: 0.6113 - val_loss: 0.6747\n",
      "Epoch 2/25\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 463ms/step - accuracy: 0.7504 - loss: 0.5003"
     ]
    }
   ],
   "source": [
    "def train_model(optimizer, optimizer_name):\n",
    "    model = create_model()\n",
    "    model.compile(optimizer=optimizer, loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    history = model.fit(\n",
    "        train_data,\n",
    "        epochs=25,\n",
    "        validation_data=test_data,\n",
    "        class_weight=class_weights\n",
    "    )\n",
    "\n",
    "\n",
    "    loss, accuracy = model.evaluate(test_data)\n",
    "    print(f'Test loss with {optimizer_name}: {loss*100:.4f}')\n",
    "    print(f'Test accuracy with {optimizer_name}: {accuracy*100:.4f}')\n",
    "\n",
    "    highest_val_accuracy = max(history.history['val_accuracy'])\n",
    "    print(f'Highest Validation Accuracy with {optimizer_name}: {highest_val_accuracy * 100:.2f}%')\n",
    "\n",
    "\n",
    "    model.save(f'model_{optimizer_name}.h5')\n",
    "    print(f\"Model saved as model_{optimizer_name}.h5\")\n",
    "\n",
    "    return history\n",
    "\n",
    "optimizers = {\n",
    "    'SGD': SGD(learning_rate=0.001),\n",
    "    'Adagrad': Adagrad(learning_rate=0.01),\n",
    "    'Adadelta': Adadelta(learning_rate=0.01),\n",
    "    'RMSProp': RMSprop(learning_rate=0.001),\n",
    "    'Adam': Adam(learning_rate=0.0001)\n",
    "}\n",
    "\n",
    "histories = {}\n",
    "for opt_name, opt in optimizers.items():\n",
    "    print(f\"Training with {opt_name} optimizer\")\n",
    "    histories[opt_name] = train_model(opt, opt_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4d54d130-e6f7-4040-8083-bbb828eeb513",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with Adam optimizer\n",
      "Epoch 1/25\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 505ms/step - accuracy: 0.6966 - loss: 0.6010 - val_accuracy: 0.6877 - val_loss: 0.6544\n",
      "Epoch 2/25\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 478ms/step - accuracy: 0.8274 - loss: 0.3723 - val_accuracy: 0.7276 - val_loss: 0.5801\n",
      "Epoch 3/25\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 440ms/step - accuracy: 0.8484 - loss: 0.3281 - val_accuracy: 0.6678 - val_loss: 0.6225\n",
      "Epoch 4/25\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 447ms/step - accuracy: 0.8427 - loss: 0.3399 - val_accuracy: 0.7442 - val_loss: 0.4504\n",
      "Epoch 5/25\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 436ms/step - accuracy: 0.8689 - loss: 0.2851 - val_accuracy: 0.8073 - val_loss: 0.4140\n",
      "Epoch 6/25\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 441ms/step - accuracy: 0.8666 - loss: 0.2617 - val_accuracy: 0.8173 - val_loss: 0.3794\n",
      "Epoch 7/25\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 442ms/step - accuracy: 0.8951 - loss: 0.2426 - val_accuracy: 0.8206 - val_loss: 0.4062\n",
      "Epoch 8/25\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 456ms/step - accuracy: 0.8689 - loss: 0.2588 - val_accuracy: 0.8306 - val_loss: 0.3885\n",
      "Epoch 9/25\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 435ms/step - accuracy: 0.8923 - loss: 0.2159 - val_accuracy: 0.8405 - val_loss: 0.3367\n",
      "Epoch 10/25\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 440ms/step - accuracy: 0.9117 - loss: 0.2008 - val_accuracy: 0.8007 - val_loss: 0.5157\n",
      "Epoch 11/25\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 440ms/step - accuracy: 0.9038 - loss: 0.1978 - val_accuracy: 0.8804 - val_loss: 0.2823\n",
      "Epoch 12/25\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 445ms/step - accuracy: 0.9292 - loss: 0.1530 - val_accuracy: 0.8904 - val_loss: 0.3069\n",
      "Epoch 13/25\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 443ms/step - accuracy: 0.9194 - loss: 0.1612 - val_accuracy: 0.8970 - val_loss: 0.2402\n",
      "Epoch 14/25\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 442ms/step - accuracy: 0.9365 - loss: 0.1457 - val_accuracy: 0.8571 - val_loss: 0.3100\n",
      "Epoch 15/25\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 444ms/step - accuracy: 0.9491 - loss: 0.1202 - val_accuracy: 0.9203 - val_loss: 0.2127\n",
      "Epoch 16/25\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 443ms/step - accuracy: 0.9543 - loss: 0.1125 - val_accuracy: 0.9169 - val_loss: 0.2091\n",
      "Epoch 17/25\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 444ms/step - accuracy: 0.9642 - loss: 0.1004 - val_accuracy: 0.9402 - val_loss: 0.1581\n",
      "Epoch 18/25\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 467ms/step - accuracy: 0.9730 - loss: 0.0754 - val_accuracy: 0.9302 - val_loss: 0.1879\n",
      "Epoch 19/25\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 450ms/step - accuracy: 0.9678 - loss: 0.0798 - val_accuracy: 0.9801 - val_loss: 0.1139\n",
      "Epoch 20/25\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 435ms/step - accuracy: 0.9855 - loss: 0.0534 - val_accuracy: 0.9934 - val_loss: 0.0704\n",
      "Epoch 21/25\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 437ms/step - accuracy: 0.9702 - loss: 0.0761 - val_accuracy: 0.9834 - val_loss: 0.0714\n",
      "Epoch 22/25\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 437ms/step - accuracy: 0.9874 - loss: 0.0528 - val_accuracy: 0.9601 - val_loss: 0.1013\n",
      "Epoch 23/25\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 435ms/step - accuracy: 0.9875 - loss: 0.0428 - val_accuracy: 0.9734 - val_loss: 0.0850\n",
      "Epoch 24/25\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 439ms/step - accuracy: 0.9929 - loss: 0.0328 - val_accuracy: 0.9934 - val_loss: 0.0533\n",
      "Epoch 25/25\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 434ms/step - accuracy: 0.9821 - loss: 0.0439 - val_accuracy: 0.9801 - val_loss: 0.0662\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 186ms/step - accuracy: 0.9847 - loss: 0.0604\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss with Adam: 6.6228\n",
      "Test accuracy with Adam: 98.0066\n",
      "Highest Validation Accuracy with Adam: 99.34%\n",
      "Model saved as model_Adam.h5\n"
     ]
    }
   ],
   "source": [
    "def train_model(optimizer, optimizer_name):\n",
    "    model = create_model()\n",
    "    model.compile(optimizer=optimizer, loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    history = model.fit(\n",
    "        train_data,\n",
    "        epochs=25,\n",
    "        validation_data=test_data,\n",
    "        class_weight=class_weights\n",
    "    )\n",
    "\n",
    "\n",
    "    loss, accuracy = model.evaluate(test_data)\n",
    "    print(f'Test loss with {optimizer_name}: {loss*100:.4f}')\n",
    "    print(f'Test accuracy with {optimizer_name}: {accuracy*100:.4f}')\n",
    "\n",
    "    highest_val_accuracy = max(history.history['val_accuracy'])\n",
    "    print(f'Highest Validation Accuracy with {optimizer_name}: {highest_val_accuracy * 100:.2f}%')\n",
    "\n",
    "\n",
    "    model.save(f'model_{optimizer_name}.h5')\n",
    "    print(f\"Model saved as model_{optimizer_name}.h5\")\n",
    "\n",
    "    return history\n",
    "\n",
    "optimizers = {\n",
    "    # 'SGD': SGD(learning_rate=0.001),\n",
    "    # 'Adagrad': Adagrad(learning_rate=0.01),\n",
    "    # 'Adadelta': Adadelta(learning_rate=0.01),\n",
    "    # 'RMSProp': RMSprop(learning_rate=0.001),\n",
    "    'Adam': Adam(learning_rate=0.0001)\n",
    "}\n",
    "\n",
    "histories = {}\n",
    "for opt_name, opt in optimizers.items():\n",
    "    print(f\"Training with {opt_name} optimizer\")\n",
    "    histories[opt_name] = train_model(opt, opt_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2169b961-2eaf-46eb-a98d-9afe6e5dd1e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[[1.         1.         1.        ]\n",
      "   [1.         1.         1.        ]\n",
      "   [1.         1.         1.        ]\n",
      "   ...\n",
      "   [1.         0.94509804 0.9254902 ]\n",
      "   [0.9882353  0.99607843 1.        ]\n",
      "   [1.         1.         1.        ]]\n",
      "\n",
      "  [[1.         1.         1.        ]\n",
      "   [1.         1.         1.        ]\n",
      "   [1.         1.         1.        ]\n",
      "   ...\n",
      "   [0.19607843 0.17254902 0.        ]\n",
      "   [1.         0.99215686 1.        ]\n",
      "   [1.         1.         1.        ]]\n",
      "\n",
      "  [[1.         1.         1.        ]\n",
      "   [1.         1.         1.        ]\n",
      "   [1.         1.         1.        ]\n",
      "   ...\n",
      "   [0.2        0.14901961 0.        ]\n",
      "   [0.99607843 0.99215686 1.        ]\n",
      "   [1.         1.         1.        ]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[1.         1.         1.        ]\n",
      "   [1.         1.         1.        ]\n",
      "   [1.         1.         1.        ]\n",
      "   ...\n",
      "   [0.9843137  0.9843137  0.9843137 ]\n",
      "   [0.99215686 0.99215686 0.99215686]\n",
      "   [0.48235294 0.48235294 0.48235294]]\n",
      "\n",
      "  [[1.         1.         1.        ]\n",
      "   [1.         1.         1.        ]\n",
      "   [1.         1.         1.        ]\n",
      "   ...\n",
      "   [1.         1.         1.        ]\n",
      "   [0.9490196  0.9490196  0.9490196 ]\n",
      "   [0.95686275 0.95686275 0.95686275]]\n",
      "\n",
      "  [[1.         1.         1.        ]\n",
      "   [1.         1.         1.        ]\n",
      "   [1.         1.         1.        ]\n",
      "   ...\n",
      "   [1.         1.         1.        ]\n",
      "   [1.         1.         1.        ]\n",
      "   [1.         1.         1.        ]]]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 178ms/step\n",
      "[[0.88173413 0.11826584]]\n",
      "{0: 'healthy', 1: 'unhealthy'}\n",
      "0\n",
      "Predicted class: healthy\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.preprocessing import image\n",
    "import numpy as np\n",
    "\n",
    "def preprocess_image(img_path):\n",
    "    img = image.load_img(img_path, target_size=(150, 150))\n",
    "    img_array = image.img_to_array(img)\n",
    "    img_array = np.expand_dims(img_array, axis=0)\n",
    "    img_array /= 255.0  # Rescale the image\n",
    "    return img_array\n",
    "\n",
    "# Example image path (update with your actual image path)\n",
    "img_path = 'Gammatonegram_images/Gammatone of heart sounds/Gammatone of heart sounds/val/healthy/a0007.jpg'\n",
    "# Preprocess the image\n",
    "img_array = preprocess_image(img_path)\n",
    "\n",
    "print(img_array)\n",
    "\n",
    "# Load a saved model\n",
    "model_path = 'model_Adam.h5'  # Replace with the correct model file name if different\n",
    "model = load_model(model_path)\n",
    "\n",
    "# Make predictions using the loaded model\n",
    "predictions = model.predict(img_array)\n",
    "print(predictions)\n",
    "predicted_class = np.argmax(predictions, axis=1)\n",
    "\n",
    "# Assuming `train_data` has `class_indices` for label decoding\n",
    "class_labels = {v: k for k, v in train_data.class_indices.items()}  # Get class labels from the training data\n",
    "print(class_labels)\n",
    "print(predicted_class[0])\n",
    "predicted_label = class_labels[predicted_class[0]]\n",
    "\n",
    "print(f'Predicted class: {predicted_label}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5cee4d4d-67aa-4f4d-b1f8-08dc165e1be3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 202ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 102ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 92ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 92ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 155ms/step\n",
      "Confusion Matrix:\n",
      "[[144   6]\n",
      " [  0 151]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Healthy       1.00      0.96      0.98       150\n",
      "   Unhealthy       0.96      1.00      0.98       151\n",
      "\n",
      "    accuracy                           0.98       301\n",
      "   macro avg       0.98      0.98      0.98       301\n",
      "weighted avg       0.98      0.98      0.98       301\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load trained model\n",
    "model_path = 'model_Adam_main.h5'  # Update with the correct model path\n",
    "model = tf.keras.models.load_model(model_path)\n",
    "\n",
    "# Get true labels and predictions\n",
    "y_true = []\n",
    "y_pred = []\n",
    "\n",
    "for images, labels in test_data:\n",
    "    preds = model.predict(images)\n",
    "    y_true.extend(labels)\n",
    "    y_pred.extend(np.argmax(preds, axis=1))\n",
    "    \n",
    "    if len(y_true) >= test_data.samples:  # Ensure we only use test set size\n",
    "        break\n",
    "\n",
    "# Convert to numpy arrays\n",
    "y_true = np.array(y_true)\n",
    "y_pred = np.array(y_pred)\n",
    "\n",
    "# Compute confusion matrix\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(cm)\n",
    "\n",
    "# Plot confusion matrix\n",
    "plt.figure(figsize=(6, 5))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=['Healthy', 'Unhealthy'], yticklabels=['Healthy', 'Unhealthy'])\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()\n",
    "\n",
    "# Compute classification report\n",
    "report = classification_report(y_true, y_pred, target_names=['Healthy', 'Unhealthy'])\n",
    "print(\"Classification Report:\")\n",
    "print(report)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8b18c02a-24ec-4a1a-a9fb-843caa3118c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Optimizers</th>\n",
       "      <th>Base_Paper_Accuracy</th>\n",
       "      <th>Obtained_Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SGD Optimizer</td>\n",
       "      <td>89.36%</td>\n",
       "      <td>89.70%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Adagrad Optimizer</td>\n",
       "      <td>93.68%</td>\n",
       "      <td>96.01%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Adadelta Optimizer</td>\n",
       "      <td>87.37%</td>\n",
       "      <td>96.68%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RMSProp Optimizer</td>\n",
       "      <td>80.73%</td>\n",
       "      <td>82.39%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Adam Optimizer</td>\n",
       "      <td>99.29%</td>\n",
       "      <td>99.34%</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Optimizers Base_Paper_Accuracy Obtained_Accuracy\n",
       "0       SGD Optimizer              89.36%            89.70%\n",
       "1   Adagrad Optimizer              93.68%            96.01%\n",
       "2  Adadelta Optimizer              87.37%            96.68%\n",
       "3   RMSProp Optimizer              80.73%            82.39%\n",
       "4      Adam Optimizer              99.29%            99.34%"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "optimizers=np.array(['SGD Optimizer','Adagrad Optimizer','Adadelta Optimizer','RMSProp Optimizer','Adam Optimizer'])\n",
    "test1= np.array(['89.36%','93.68%','87.37%','80.73%','99.29%'])\n",
    "testt2=np.array(['89.70%','96.01%','96.68%','82.39%','99.34%'])\n",
    "\n",
    "df=pd.DataFrame({'Optimizers':optimizers,'Base_Paper_Accuracy':test1,'Obtained_Accuracy':testt2})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d0cefc82-68af-48f4-98f8-413f1a549581",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications import VGG16\n",
    "from tensorflow.keras.layers import Flatten, Dense, BatchNormalization, Activation\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras import Model\n",
    "\n",
    "def create_model():\n",
    "    # Load the VGG16 model, excluding the top layers (fully connected layers)\n",
    "    vgg16 = VGG16(weights='imagenet', include_top=False, input_shape=(150, 150, 3))\n",
    "\n",
    "    # Freeze the layers in VGG16 so their weights don't get updated during training\n",
    "    for layer in vgg16.layers:\n",
    "        layer.trainable = False\n",
    "\n",
    "    # Add custom layers on top of VGG16\n",
    "    model = Sequential()\n",
    "    model.add(vgg16)\n",
    "    \n",
    "    # Add custom layers\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(128))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dense(64))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dense(2, activation='softmax'))  # Adjust the output layer as per your classification task\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a2d509a8-55ad-43dc-9655-4c53608cbff0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with Adam optimizer\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "\u001b[1m58889256/58889256\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 0us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DELL\\anaconda3\\Lib\\site-packages\\keras\\src\\trainers\\data_adapters\\py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m310s\u001b[0m 3s/step - accuracy: 0.5795 - loss: 0.6555 - val_accuracy: 0.6744 - val_loss: 0.5600\n",
      "Epoch 2/25\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m309s\u001b[0m 3s/step - accuracy: 0.7696 - loss: 0.4933 - val_accuracy: 0.6545 - val_loss: 0.5956\n",
      "Epoch 3/25\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m310s\u001b[0m 3s/step - accuracy: 0.7859 - loss: 0.4395 - val_accuracy: 0.7375 - val_loss: 0.5202\n",
      "Epoch 4/25\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m309s\u001b[0m 3s/step - accuracy: 0.8059 - loss: 0.3976 - val_accuracy: 0.6877 - val_loss: 0.5346\n",
      "Epoch 5/25\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m308s\u001b[0m 3s/step - accuracy: 0.8181 - loss: 0.3762 - val_accuracy: 0.7542 - val_loss: 0.4975\n",
      "Epoch 6/25\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m306s\u001b[0m 3s/step - accuracy: 0.8255 - loss: 0.3561 - val_accuracy: 0.7309 - val_loss: 0.5096\n",
      "Epoch 7/25\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m308s\u001b[0m 3s/step - accuracy: 0.8260 - loss: 0.3471 - val_accuracy: 0.6512 - val_loss: 0.7154\n",
      "Epoch 8/25\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m314s\u001b[0m 3s/step - accuracy: 0.8060 - loss: 0.3631 - val_accuracy: 0.7442 - val_loss: 0.4937\n",
      "Epoch 9/25\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m315s\u001b[0m 3s/step - accuracy: 0.8487 - loss: 0.3249 - val_accuracy: 0.7243 - val_loss: 0.5012\n",
      "Epoch 10/25\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m316s\u001b[0m 3s/step - accuracy: 0.8322 - loss: 0.3212 - val_accuracy: 0.7309 - val_loss: 0.5146\n",
      "Epoch 11/25\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3098s\u001b[0m 31s/step - accuracy: 0.8425 - loss: 0.3098 - val_accuracy: 0.7342 - val_loss: 0.5247\n",
      "Epoch 12/25\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m594s\u001b[0m 6s/step - accuracy: 0.8647 - loss: 0.2967 - val_accuracy: 0.7409 - val_loss: 0.4701\n",
      "Epoch 13/25\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m316s\u001b[0m 3s/step - accuracy: 0.8463 - loss: 0.3031 - val_accuracy: 0.7608 - val_loss: 0.4661\n",
      "Epoch 14/25\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m270s\u001b[0m 3s/step - accuracy: 0.8680 - loss: 0.2947 - val_accuracy: 0.6645 - val_loss: 0.7154\n",
      "Epoch 15/25\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m258s\u001b[0m 3s/step - accuracy: 0.8385 - loss: 0.3175 - val_accuracy: 0.6877 - val_loss: 0.6008\n",
      "Epoch 16/25\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m236s\u001b[0m 2s/step - accuracy: 0.8584 - loss: 0.2870 - val_accuracy: 0.7542 - val_loss: 0.4709\n",
      "Epoch 17/25\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m226s\u001b[0m 2s/step - accuracy: 0.8476 - loss: 0.3097 - val_accuracy: 0.7475 - val_loss: 0.4746\n",
      "Epoch 18/25\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m221s\u001b[0m 2s/step - accuracy: 0.8531 - loss: 0.2894 - val_accuracy: 0.7375 - val_loss: 0.4777\n",
      "Epoch 19/25\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m221s\u001b[0m 2s/step - accuracy: 0.8531 - loss: 0.3062 - val_accuracy: 0.7475 - val_loss: 0.4644\n",
      "Epoch 20/25\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m208s\u001b[0m 2s/step - accuracy: 0.8711 - loss: 0.2705 - val_accuracy: 0.6977 - val_loss: 0.5654\n",
      "Epoch 21/25\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m212s\u001b[0m 2s/step - accuracy: 0.8765 - loss: 0.2682 - val_accuracy: 0.7674 - val_loss: 0.4343\n",
      "Epoch 22/25\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m216s\u001b[0m 2s/step - accuracy: 0.8797 - loss: 0.2572 - val_accuracy: 0.7176 - val_loss: 0.5411\n",
      "Epoch 23/25\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m216s\u001b[0m 2s/step - accuracy: 0.8643 - loss: 0.2579 - val_accuracy: 0.7774 - val_loss: 0.4192\n",
      "Epoch 24/25\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m219s\u001b[0m 2s/step - accuracy: 0.8673 - loss: 0.2529 - val_accuracy: 0.7442 - val_loss: 0.4739\n",
      "Epoch 25/25\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m220s\u001b[0m 2s/step - accuracy: 0.8704 - loss: 0.2627 - val_accuracy: 0.7807 - val_loss: 0.4229\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 2s/step - accuracy: 0.7718 - loss: 0.4139\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss with Adam: 42.2871\n",
      "Test accuracy with Adam: 78.0731\n",
      "Highest Validation Accuracy with Adam: 78.07%\n",
      "Model saved as model_Adam.h5\n"
     ]
    }
   ],
   "source": [
    "def train_model(optimizer, optimizer_name):\n",
    "    model = create_model()\n",
    "    model.compile(optimizer=optimizer, loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    history = model.fit(\n",
    "        train_data,\n",
    "        epochs=25,\n",
    "        validation_data=test_data,\n",
    "        class_weight=class_weights\n",
    "    )\n",
    "\n",
    "\n",
    "    loss, accuracy = model.evaluate(test_data)\n",
    "    print(f'Test loss with {optimizer_name}: {loss*100:.4f}')\n",
    "    print(f'Test accuracy with {optimizer_name}: {accuracy*100:.4f}')\n",
    "\n",
    "    highest_val_accuracy = max(history.history['val_accuracy'])\n",
    "    print(f'Highest Validation Accuracy with {optimizer_name}: {highest_val_accuracy * 100:.2f}%')\n",
    "\n",
    "\n",
    "    model.save(f'model_{optimizer_name}.h5')\n",
    "    print(f\"Model saved as model_{optimizer_name}.h5\")\n",
    "\n",
    "    return history\n",
    "\n",
    "optimizers = {\n",
    "    # 'SGD': SGD(learning_rate=0.001),\n",
    "    # 'Adagrad': Adagrad(learning_rate=0.01),\n",
    "    # 'Adadelta': Adadelta(learning_rate=0.01),\n",
    "    # 'RMSProp': RMSprop(learning_rate=0.001),\n",
    "    'Adam': Adam(learning_rate=0.0001)\n",
    "}\n",
    "\n",
    "histories = {}\n",
    "for opt_name, opt in optimizers.items():\n",
    "    print(f\"Training with {opt_name} optimizer\")\n",
    "    histories[opt_name] = train_model(opt, opt_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ccff80c-a891-4f70-8d3f-a4c4daaf3093",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
